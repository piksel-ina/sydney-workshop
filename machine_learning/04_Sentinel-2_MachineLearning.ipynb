{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning using Sentinel-2 Data\n",
    "\n",
    "This example uses training data from the\n",
    "[Coast Train](https://github.com/nick-murray/coastTrain) dataset\n",
    "along with Sentinel-2 data to demonstrate how to use a\n",
    "machine learning classifier, in this case, Random Forest, to\n",
    "assign a class to each pixel.\n",
    "\n",
    "This notebook combines lessons from previous notebooks into\n",
    "a comprehensive worked example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "First we load the required Python libraries and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datacube import Datacube\n",
    "from ipyleaflet import basemaps\n",
    "from odc.geo.geom import point\n",
    "from odc.stac import configure_s3_access\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study site configuration\n",
    "\n",
    "Here we establish the STAC catalog we're using as well as a\n",
    "spatial and temporal extent. This can be anywhere, but the location below, the island of Sepanjang, was chosen as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a year\n",
    "year = \"2025\"\n",
    "\n",
    "# Location is the island of Sepanjang, Indonesia\n",
    "aoi_coords = -7.115, 115.83\n",
    "\n",
    "aoi_point = point(aoi_coords[1], aoi_coords[0], crs=\"EPSG:4326\")\n",
    "aoi = aoi_point.buffer(0.1).boundingbox\n",
    "\n",
    "aoi.explore(tiles=basemaps.Esri.WorldImagery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure our environment.\n",
    "\n",
    "This cell sets up Dask, which we use for parallel computing, and configures\n",
    "AWS credentials for \"unsigned\" (public) data access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"\n",
    "\n",
    "# Configure S3 access for datacube\n",
    "configure_s3_access(no_sign_request=True)\n",
    "\n",
    "# Set up the Datacube\n",
    "dc = Datacube(app=\"Sentinel-2_MachineLearning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a function to prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(ds):\n",
    "    # Scale Sentinel-2 data to reflectance\n",
    "    data = (ds * 0.0001).clip(0, 1)\n",
    "\n",
    "    # Add some indices to improve classification results\n",
    "    # MNDWI for water\n",
    "    data[\"mndwi\"] = (data.green - data.swir16) / (data.green + data.swir16)\n",
    "\n",
    "    # NDVI for vegetation\n",
    "    data[\"ndvi\"] = (data.nir08 - data.red) / (data.nir08 + data.red)\n",
    "\n",
    "    # NDTI for additional distinction of shallow benthic types\n",
    "    data[\"ndti\"] = (data.red - data.green) / (data.red + data.green)\n",
    "\n",
    "    # Natural log of blue/green for shallow water definition\n",
    "    data[\"ln_bg\"] = np.log(data.blue / data.green)\n",
    "\n",
    "    # Modified form of MVI (Baloloy et al. 2020) for distinguishing between mangroves and other vegetation types\n",
    "    data[\"mvi\"] = (((data.nir08 - data.green) / (data.swir16 - data.green)) * 0.1).clip(\n",
    "        -1, 1\n",
    "    )\n",
    "\n",
    "    # Remove the time dimension\n",
    "    return data.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "Next up we gather training data. This could be any geospatial point dataset\n",
    "with a column that is numeric, for the class.\n",
    "\n",
    "If you'd like to explore the structure of this data, you can run `gdf.head()`\n",
    "to see the first few rows. The `explore()` function with the `column` argument\n",
    "will show the data on the map, and change the colour based on that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training data\n",
    "data_url = \"./NusaTenggaraBarat_tdata.geojson\"\n",
    "gdf = gpd.read_file(data_url, bbox=tuple(aoi))\n",
    "\n",
    "# Alternately, use your updated data if you have it.\n",
    "# gdf = gpd.read_file(\"data/training_revised.geojson\", bbox=bbox)\n",
    "gdf.explore(\n",
    "    column=\"Ecosys_Typ\",\n",
    "    legend=True,\n",
    "    tiles=basemaps.Esri.WorldImagery,\n",
    "    style_kwds={\"radius\": 5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and load Sentinel-2 data\n",
    "\n",
    "Here we search for Sentinel-2 scenes over our study area and use\n",
    "Dask to lazy-load them. We're only loading the red, green, blue, nir and swir\n",
    "bands, along with the scene classification (scl) band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the Sentinel-2 GeoMAD\n",
    "ds = dc.load(\n",
    "    product=\"s2_l2a\",\n",
    "    longitude=(aoi.left, aoi.right),\n",
    "    latitude=(aoi.bottom, aoi.top),\n",
    "    time=(f\"{year}-01-01/{year}-12-31\"),\n",
    "    # output_crs=\"EPSG:6933\",\n",
    "    # resolution=10,\n",
    "    measurements=[\"blue\", \"green\", \"red\", \"nir08\", \"swir16\", \"swir22\"],\n",
    "    group_by=\"solar_day\",\n",
    "    dask_chunks={\"time\": 1, \"x\": 3200, \"y\": 3200},\n",
    "    resampling={\n",
    "        \"*\": \"cubic\",\n",
    "        \"scl\": \"nearest\",\n",
    "    },\n",
    "    driver=\"rio\",\n",
    ")\n",
    "\n",
    "data = prepare_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data array\n",
    "\n",
    "This next step involves extracting observed values from the satellite data\n",
    "and combining them with our cover class data, resulting in something like this:\n",
    "\n",
    "`class, red, green, blue ...`\n",
    "\n",
    "This structure establishes a set of classes and the spectral information associated with them. This is the groundwork for our machine learning classifier, which will identify (hidden) statistical relationships between spectral variables and cover classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First transform the training points to the same CRS as the data\n",
    "training = gdf.to_crs(data.odc.geobox.crs)\n",
    "\n",
    "# Next get the X and Y values out of the point geometries\n",
    "training_da = training.assign(x=training.geometry.x, y=training.geometry.y).to_xarray()\n",
    "\n",
    "# Now we can use the x and y values (lon, lat) to extract values from the median composite\n",
    "training_values = (\n",
    "    data.sel(training_da[[\"x\", \"y\"]], method=\"nearest\")\n",
    "    .squeeze()\n",
    "    .compute()\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "# Join the training data with the extracted values and remove unnecessary columns\n",
    "training_array = pd.concat([training[\"Class\"], training_values], axis=1)\n",
    "training_array = training_array.drop(\n",
    "    columns=[\n",
    "        \"y\",\n",
    "        \"x\",\n",
    "        \"spatial_ref\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Drop rows where there was no data available\n",
    "training_array = training_array.dropna()\n",
    "\n",
    "# Preview our resulting training array\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a classifier and fit a model\n",
    "\n",
    "We pass in two numpy arrays to the classifier, one has the observations (reflectance values, vegetation indices, and so on) while the other has the cover classes.\n",
    "\n",
    "First, we need to split our point data into training and test sets. The training set is used to train the machine learning model, while the test set is used to measure the accuracy of the classification. This is very important, as it helps with refining the model and communicating reliability of the outputs.\n",
    "\n",
    "We can also produce an initial report of classification accuracy. This uses only the data in our training and testing arrays. The classifier, developed using the training subset, is applied to the testing subset. This provides us class-by-class measures of accuracy, showing which classes are more or less accurately classified. \n",
    "\n",
    "Note that interpreting these accuracy figures is not simple as simple as it seems, and it is easy to get artificially high values, especially with low sample numbers or spatially clustered samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classes are the first column\n",
    "classes = np.array(training_array)[:, 0]\n",
    "# The observation data is everything after the first column\n",
    "observations = np.array(training_array)[:, 1:]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    observations, classes, test_size=0.3, stratify=classes\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "# Create a model...\n",
    "classifier = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\")\n",
    "# Consider other hyperparameters - max_features, max_depth, min_samples_split, min_samples_leaf, bootstrap\n",
    "# Consider also k-fold cross-validation at this stage\n",
    "\n",
    "# ...and fit it to the training data\n",
    "model = classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "class_names = gdf.groupby(\"Class\")[\"Ecosys_Typ\"].first().sort_index().values\n",
    "print(\n",
    "    f\"\\nClassification report:\\n{classification_report(y_test, y_pred, target_names=class_names)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "Next we apply our machine learning to the entire image to predict the class in each pixel. Again, we need a simple numpy array, this time\n",
    "just with the observations. This needs to be in long array where\n",
    "the x dimension is the observation values and the y is each cell\n",
    "in the original raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a stacked array of observations\n",
    "stacked_arrays = data.to_array().stack(dims=[\"y\", \"x\"]).transpose()\n",
    "\n",
    "# Replace any NaN values with 0\n",
    "stacked_arrays = stacked_arrays.fillna(0)\n",
    "\n",
    "# Predict the classes using our trained model\n",
    "predicted = model.predict(stacked_arrays)\n",
    "\n",
    "# Reshape back to the original 2D array\n",
    "array = predicted.reshape(len(data.y), len(data.x))\n",
    "\n",
    "# Convert to an xarray again, because it's easier to work with\n",
    "predicted_da = xr.DataArray(array, coords={\"y\": data.y, \"x\": data.x}, dims=[\"y\", \"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise our results\n",
    "\n",
    "Here we're visualising the results along with the RGB image\n",
    "and the original training data points. We're doing this using\n",
    "a Python library called Folium, which wraps up the Leaflet\n",
    "JavaScript library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all on a single interactive map\n",
    "m = folium.Map(\n",
    "    location=tuple(aoi_point.coords[0][::-1]),\n",
    "    zoom_start=11,\n",
    "    tiles=basemaps.Esri.WorldImagery,\n",
    ")\n",
    "\n",
    "# RGB for the median\n",
    "data.odc.to_rgba(bands=[\"red\", \"green\", \"blue\"], vmin=0, vmax=0.3).odc.add_to(\n",
    "    m, name=\"Median Composite\"\n",
    ")\n",
    "\n",
    "# Categorical for the predicted classes and for the training data\n",
    "# Note that Alex couldn't find a way to use the colormap here, so colours are random!\n",
    "predicted_da.astype(int).odc.add_to(m, name=\"Predicted\", opacity=0.7)\n",
    "\n",
    "gdf.explore(\n",
    "    m=m,\n",
    "    column=\"Ecosys_Typ\",\n",
    "    name=\"Training Data\",\n",
    "    style_kwds={\n",
    "        \"radius\": 5,\n",
    "        \"stroke\": \"white\",\n",
    "        \"opacity\": 1,\n",
    "        \"color\": \"white\",\n",
    "        \"stroke-weight\": 0.8,\n",
    "    },\n",
    "    categorical=True,\n",
    ")\n",
    "\n",
    "# Layer control\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test importance of model variables\n",
    "\n",
    "Random Forests can provide some useful explanatory information. Random Forest models make a large number of decisions based on band/index values. Feature importance tells us which bands/indices contribute to the greatest number of decisions.\n",
    "\n",
    "Feature importance can be useful in a number of ways. If efficiency is important, a model may be able to be simplified by removing low-importance features. Feature importance can help to refine flawed models, such as those that confuse classes often. \n",
    "\n",
    "Feature importance can also inform sensor design for related missions. For example, if we were planning to expand a project using UAV data, we might select the UAV sensor partly based on band importance.\n",
    "\n",
    "It is also worth noting that feature importance depends partly upon the classes themselves. For instance, in this model, MNDWI has high importance. How would this change if we masked out land areas, and only classified benthic cover?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature names (band names from training data) Note that order has to be maintained here\n",
    "feature_names = list(data.data_vars)\n",
    "\n",
    "importance_df = pd.DataFrame(\n",
    "    {\"Feature\": feature_names, \"Importance\": model.feature_importances_}\n",
    ").sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the model to a different area\n",
    "\n",
    "We will now apply the same machine learning model to a different location. This can be done without retraining the model. The first cell below just defines functions to perform all the same pre-processing we did for our original site (retrieving S2 images, masking cloud, adding indices, producing median image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can transfer the classification to the similar nearby island of Raas, using the same model\n",
    "raas_coords = -7.135, 114.58\n",
    "\n",
    "new_point = point(raas_coords[1], raas_coords[0], crs=\"EPSG:4326\")\n",
    "new_aoi = new_point.buffer(0.11).boundingbox\n",
    "new_aoi.explore(tiles=basemaps.Esri.WorldImagery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from the Sentinel-2 GeoMAD\n",
    "new_ds = dc.load(\n",
    "    product=\"s2_l2a\",\n",
    "    longitude=(new_aoi.left, new_aoi.right),\n",
    "    latitude=(new_aoi.bottom, new_aoi.top),\n",
    "    time=(f\"{year}-01-01/{year}-12-31\"),\n",
    "    # output_crs=\"EPSG:6933\",\n",
    "    # resolution=10,\n",
    "    measurements=[\"blue\", \"green\", \"red\", \"nir08\", \"swir16\", \"swir22\"],\n",
    "    group_by=\"solar_day\",\n",
    "    dask_chunks={\"time\": 1, \"x\": 3200, \"y\": 3200},\n",
    "    resampling={\n",
    "        \"*\": \"cubic\",\n",
    "        \"scl\": \"nearest\",\n",
    "    },\n",
    "    driver=\"rio\",\n",
    ")\n",
    "\n",
    "new_data = prepare_data(new_ds)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a new area. We can use the nearby island of Raas, which has similar land and benthic cover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell applies our machine learning model, developed using data in Sapeken, to Raas. This can be carried out without changing the model at all, and we can expect it to work fairly well. Spatially transferring a random forest model like this will work best only if the areas have similar land cover types, and the images are sourced from the same sensor and processed identically.\n",
    "\n",
    "Some very advanced deep learning models can operate across domains - for instance, being generalisable across different satellite sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a stacked array of observations\n",
    "stacked_arrays_new = new_data.to_array().stack(dims=[\"y\", \"x\"]).transpose()\n",
    "\n",
    "# Replace any NaN values with 0\n",
    "stacked_arrays_new = stacked_arrays_new.fillna(0)\n",
    "\n",
    "# Predict the classes\n",
    "predicted_new = model.predict(stacked_arrays_new)\n",
    "\n",
    "# Reshape back to the original 2D array\n",
    "array_new = predicted_new.reshape(len(new_data.y), len(new_data.x))\n",
    "\n",
    "# Convert to an xarray again, because it's easier to work with\n",
    "predicted_da_new = xr.DataArray(\n",
    "    array_new, coords={\"y\": new_data.y, \"x\": new_data.x}, dims=[\"y\", \"x\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise the newly classified area\n",
    "\n",
    "Now we can visualise the classification outputs for Raas. The classification symbology will be the same as the previous map. We can see that, even without modifying the model at all, it works quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(\n",
    "    location=tuple(new_point.coords[0][::-1]),\n",
    "    zoom_start=11,\n",
    "    tiles=basemaps.Esri.WorldImagery,\n",
    ")\n",
    "\n",
    "# RGB for the median\n",
    "new_data.odc.to_rgba(bands=[\"red\", \"green\", \"blue\"], vmin=0, vmax=0.3).odc.add_to(\n",
    "    m, name=\"Median Composite\"\n",
    ")\n",
    "\n",
    "# Categorical for the predicted classes and for the training data\n",
    "predicted_da_new.odc.add_to(m, name=\"Predicted_raas\", opacity=0.7)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the RGB median to use as a base for updating training data\n",
    "# median.to_array(dim='band').odc.write_cog(\n",
    "#     data_url.replace(\"_tdata.geojson\", \"_median.tif\"),\n",
    "#     overwrite=True\n",
    "# )\n",
    "# # Export the training data, to update with the more data\n",
    "# gdf[[\"Class\", \"Ecosys_Typ\", \"geometry\"]].to_file(\n",
    "#     data_url.replace(\"_tddata.geojson\", \"_revised.geojson\"), driver=\"GeoJSON\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Do the results make sense?\n",
    "\n",
    "Are there any issues with the training and testing data? If so, how could they be fixed?\n",
    "\n",
    "There are limitations with the visualisation used here - consider exporting the outputs to view them in QGIS or similar\n",
    "\n",
    "### Fine tuning\n",
    "\n",
    "The obvious next step is to fine tune the data. There are a few ways you can do this:\n",
    "- Adding more input features into the model (e.g. vegetation indices)\n",
    "- Modifying model training data\n",
    "- Training the model on data from both sites"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
